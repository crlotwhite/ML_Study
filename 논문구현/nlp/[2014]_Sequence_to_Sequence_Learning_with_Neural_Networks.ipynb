{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLKngyfMQ-qB"
      },
      "source": [
        "# Data Prepairing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z3mnzF4z7YN",
        "outputId": "32b64f72-93a2-4796-9b1d-fab94b88732a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate --upgrade -q\n",
        "!pip install spacy --upgrade -q\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kD8Mmdd0s1Aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77586496-dc61-4552-baba-18d207d75bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import spacy\n",
        "import datasets\n",
        "from torchtext import vocab\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs1OaglUzpQq",
        "outputId": "a5547159-8821-494a-fd49-202c4b707973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "dataset = datasets.load_dataset(\"bentrevett/multi30k\")\n",
        "\n",
        "train_data, valid_data, test_data = (\n",
        "    dataset[\"train\"],\n",
        "    dataset[\"validation\"],\n",
        "    dataset[\"test\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "def tokenize_and_lower(s, key):\n",
        "    global en_nlp, de_nlp, max_length\n",
        "\n",
        "    if key == 'en':\n",
        "        nlp = en_nlp\n",
        "        text = s['en']\n",
        "    elif key == 'de':\n",
        "        nlp = de_nlp\n",
        "        text = s['de']\n",
        "    else:\n",
        "        raise ValueError(\"Invalid key. Expected 'en' or 'de'.\")\n",
        "\n",
        "    return [token.text.lower() for token in nlp.tokenizer(text)][:max_length]\n",
        "\n",
        "tokenize_en = partial(tokenize_and_lower, key='en')\n",
        "tokenize_de = partial(tokenize_and_lower, key='de')\n",
        "\n",
        "en_nlp = spacy.load(\"en_core_web_sm\")\n",
        "de_nlp = spacy.load(\"de_core_news_sm\")\n",
        "\n",
        "min_freq = 2\n",
        "max_length = 100\n",
        "convert_to_lowercase = True\n",
        "sos_token = \"<sos>\"\n",
        "eos_token = \"<eos>\"\n",
        "unk_token = \"<unk>\"\n",
        "pad_token = \"<pad>\"\n",
        "special_tokens = [\n",
        "    unk_token,\n",
        "    pad_token,\n",
        "    sos_token,\n",
        "    eos_token,\n",
        "]\n",
        "\n",
        "en_tokens = [tokenize_en(s) for s in train_data]\n",
        "en_vocab = vocab.build_vocab_from_iterator(\n",
        "    en_tokens,\n",
        "    min_freq=min_freq,\n",
        "    specials=special_tokens,\n",
        ")\n",
        "\n",
        "de_tokens = [tokenize_de(s) for s in train_data]\n",
        "de_vocab = vocab.build_vocab_from_iterator(\n",
        "    de_tokens,\n",
        "    min_freq=min_freq,\n",
        "    specials=special_tokens,\n",
        ")\n",
        "\n",
        "unk_index = en_vocab[unk_token]\n",
        "pad_index = en_vocab[pad_token]\n",
        "\n",
        "en_vocab.set_default_index(unk_index)\n",
        "de_vocab.set_default_index(unk_index)\n"
      ],
      "metadata": {
        "id": "ab5EjqDHSruL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d55112d69eb64807a90dc895a509a165",
            "57bc7672f2ed4810aa180a884939b64a",
            "7365d15bfd5f4f74a8f4939894374586",
            "084b183b6eb04407929ef2777ee1a508",
            "ecd5f2462cdd4881b78f21d13678c15c",
            "b21464b38cd74bb685a482104acbdd5b",
            "8996fec23c744b4c817dedfe1a49d865",
            "0904b220d0e54689b9b773126b0f603c",
            "7c4ed8a230824e7789f88807465916db",
            "eece2ac489424838b4f11f2c91cd3d00",
            "083869e5409d40a48d747bd77d870d44"
          ]
        },
        "id": "WmyJLR-m0bHx",
        "outputId": "b5752a1c-9104-4251-901d-15cee298d5bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d55112d69eb64807a90dc895a509a165"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def preprocess_and_tokenize(example, en_nlp, de_nlp, max_length, sos_token, eos_token, en_vocab, de_vocab):\n",
        "    en_tokens = [sos_token] + tokenize_en(example) + [eos_token]\n",
        "    de_tokens = [sos_token] + tokenize_de(example) + [eos_token]\n",
        "    en_ids = en_vocab.lookup_indices(en_tokens)\n",
        "    de_ids = de_vocab.lookup_indices(de_tokens)\n",
        "\n",
        "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens, \"en_ids\": en_ids, \"de_ids\": de_ids}\n",
        "\n",
        "\n",
        "function_kwargs = {\n",
        "    \"en_nlp\": en_nlp,\n",
        "    \"de_nlp\": de_nlp,\n",
        "    \"max_length\": max_length,\n",
        "    \"sos_token\": sos_token,\n",
        "    \"eos_token\": eos_token,\n",
        "    \"en_vocab\": en_vocab,\n",
        "    \"de_vocab\": de_vocab\n",
        "}\n",
        "\n",
        "train_data = train_data.map(preprocess_and_tokenize, fn_kwargs=function_kwargs)\n",
        "valid_data = valid_data.map(preprocess_and_tokenize, fn_kwargs=function_kwargs)\n",
        "test_data = test_data.map(preprocess_and_tokenize, fn_kwargs=function_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_type = \"torch\"\n",
        "format_columns = [\"en_ids\", \"de_ids\"]\n",
        "\n",
        "kwargs = {\n",
        "    \"type\": \"torch\",\n",
        "    \"columns\": [\"en_ids\", \"de_ids\"],\n",
        "    \"output_all_columns\": True\n",
        "}\n",
        "\n",
        "train_data = train_data.with_format(**kwargs)\n",
        "valid_data = valid_data.with_format(**kwargs)\n",
        "test_data = test_data.with_format(**kwargs)"
      ],
      "metadata": {
        "id": "kpaalF2BFkmO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ES5jGJ694TGJ"
      },
      "outputs": [],
      "source": [
        "def create_collate_function(pad_value):\n",
        "    def collate_batch(batch):\n",
        "        english_ids = [example[\"en_ids\"] for example in batch]\n",
        "        german_ids = [example[\"de_ids\"] for example in batch]\n",
        "\n",
        "        padded_english_ids = nn.utils.rnn.pad_sequence(english_ids, padding_value=pad_value)\n",
        "        padded_german_ids = nn.utils.rnn.pad_sequence(german_ids, padding_value=pad_value)\n",
        "\n",
        "        return {\n",
        "            \"en_ids\": padded_english_ids,\n",
        "            \"de_ids\": padded_german_ids,\n",
        "        }\n",
        "\n",
        "    return collate_batch\n",
        "\n",
        "def create_data_loader(dataset, batch_size, pad_value, shuffle = False):\n",
        "    collate_function = create_collate_function(pad_value)\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_function,\n",
        "        shuffle=shuffle,\n",
        "    )\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "pad_value = 0\n",
        "\n",
        "train_data_loader = create_data_loader(train_data, batch_size, pad_value, shuffle=True)\n",
        "valid_data_loader = create_data_loader(valid_data, batch_size, pad_value)\n",
        "test_data_loader = create_data_loader(test_data, batch_size, pad_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3VGDhANRB3Z"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5uGK9y_s1Ab"
      },
      "source": [
        "## 논문 속 모델 설정\n",
        "\n",
        "- **모델 설정**:  \n",
        "  - **층 수**: 깊은 LSTM (deep LSTM) 4층  \n",
        "  - **셀 수**: 각 층당 1000개 셀  \n",
        "  - **단어 임베딩 차원**: 1000 차원  \n",
        "  - **입력 어휘 크기**: 160,000  \n",
        "  - **출력 어휘 크기**: 80,000  \n",
        "  - **문장 표현**: 8000 실수  \n",
        "  - **파라미터 개수**: 총 384M 파라미터 (그 중 64M는 순수 재발 연결)  \n",
        "- **파라미터 초기화**: -0.08과 0.08 사이의 균등 분포  \n",
        "- **학습 방법**:  \n",
        "  - **Stochastic Gradient Descent (SGD)**: 모멘텀 없이 고정된 학습률 0.7  \n",
        "  - **학습률 감소**: 5 에포크 후 매 반 에포크마다 절반으로 감소  \n",
        "  - **총 학습 에포크**: 7.5 에포크  \n",
        "- **미니배치 설정**:  \n",
        "  - 배치 크기: 128 시퀀스  \n",
        "- **폭발적 그래디언트 방지**:  \n",
        "  - 그래디언트 크기 제한 (Gradient Clipping)  \n",
        "  - 각 학습 배치에 대해, $s = \\|g\\|_2$ (g는 128로 나눈 그래디언트)  \n",
        "  - 만약 $s > 5$, $ g = \\frac{5g}{s}$  \n",
        "- **다른 문장 길이를 처리하는 방법**:  \n",
        "  - 짧은 문장 (길이 20-30)과 긴 문장 (길이 > 100)의 균형을 맞추기 위해  \n",
        "  - 미니배치 내에서 문장 길이를 비슷하게 맞춤  \n",
        "  - 2배 속도 향상"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqBXlD4gs1Ab"
      },
      "source": [
        "## 입력 순서 반전의 장점\n",
        "\n",
        "1. **짧은 단기 의존성 도입:**\n",
        "   - 원래 문장 순서에서는 소스 문장과 타겟 문장의 대응하는 단어들이 멀리 떨어져 있을 수 있습니다. 예를 들어, 원 문장에서 문장의 처음 부분에 있는 단어는 타겟 문장에서도 처음 부분에 올 가능성이 큽니다. 하지만, 그 사이의 다른 단어들 때문에 학습 모델은 이러한 대응을 찾기 어렵습니다.\n",
        "   - 입력 문장의 순서를 반전하면 소스 문장의 끝 부분에 있는 단어들이 타겟 문장의 처음 부분에 대응되고, 이로 인해 대응 단어들이 더 가까워집니다. 예를 들어, \"a, b, c\"를 \"α, β, γ\"로 매핑할 때 \"a\"와 \"α\"는 멀리 떨어진 반면, 순서를 반전시킨 \"c, b, a\"에서는 \"a\"와 \"α\"가 더 가깝게 됩니다.\n",
        "\n",
        "2. **최소 시간 지연 감소:**\n",
        "   - 소스 문장과 타겟 문장 사이의 최소 시간 지연(minimal time lag)을 줄입니다. 원래 순서에서는 소스 문장의 각 단어가 타겟 단어와 멀리 떨어져 있어 긴 시간 지연을 가지게 됩니다.\n",
        "   - 순서를 반전하면, 초기 몇 개의 단어들이 더 가까워져, 최소 시간 지연이 크게 줄어듭니다. 이렇게 되면 역전파(backpropagation) 과정에서 소스와 타겟 사이의 \"커뮤니케이션\"을 설정하기가 쉬워집니다.\n",
        "\n",
        "3. **확률 분포의 초반 부분 개선:**\n",
        "   - 입력 문장을 반전하면 초반 부분의 예측 정확도가 높아지게 됩니다. 이는 학습 초기 단계에서 신경망이 소스 단어와 타겟 단어 사이의 직접적인 관계를 더 잘 학습할 수 있음을 의미합니다.\n",
        "\n",
        "결과적으로, 이러한 방법은 소스 문장의 정보가 LSTM 네트워크 내에서 더 효과적으로 전달되고 사용되게 하여, 전반적인 번역 성능과 모델 효율성을 크게 향상시킵니다.\n",
        "이 기술적 변형이 LSTM의 기초 설계의 시퀀스 의존성 문제를 직접적으로 해결하기 때문에 학습이 더 용이해지며, 이는 특히 긴 문장 처리에 있어 큰 이점을 제공합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "01DK790ds1Ac"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_rate):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout_rate)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, input_seq) -> tuple:\n",
        "        embedded = self.dropout(self.embedding(input_seq))\n",
        "        outputs, (hidden_state, cell_state) = self.rnn(embedded)\n",
        "        return hidden_state, cell_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "djPLGtUWs1Ac"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_rate):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.output_dim = output_vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(output_vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout_rate)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, input_token, hidden_state, cell_state):\n",
        "        input_token = input_token.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input_token))\n",
        "        output, (hidden_state, cell_state) = self.rnn(embedded, (hidden_state, cell_state))\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        return prediction, hidden_state, cell_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7INjTwxds1Ac"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, input_vocab_size, output_vocab_size,\n",
        "                 embedding_dim, hidden_dim, n_layers, dropout_rate, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = Encoder(input_vocab_size,\n",
        "                               embedding_dim, hidden_dim, n_layers,\n",
        "                               dropout_rate)\n",
        "        self.decoder = Decoder(output_vocab_size,\n",
        "                               embedding_dim, hidden_dim, n_layers,\n",
        "                               dropout_rate)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src_seq, trg_seq, teacher_forcing_ratio = 0.5):\n",
        "        batch_size = trg_seq.shape[1]\n",
        "        trg_len = trg_seq.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        hidden_state, cell_state = self.encoder(src_seq)\n",
        "        input_token = trg_seq[0, :]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden_state, cell_state = self.decoder(input_token, hidden_state, cell_state)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input_token = trg_seq[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vrbQ9fb3s1Ac"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ttGqojuBs1Ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d37373-8d45-4bda-e7da-2e2a5f15172b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7853, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "input_vocab_size = len(de_vocab)\n",
        "output_vocab_size = len(en_vocab)\n",
        "embedding_dim = 256\n",
        "hidden_dim = 512\n",
        "n_layers = 2\n",
        "dropout_rate = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "seq2seq_model = Seq2Seq(input_vocab_size, output_vocab_size,\n",
        "                        embedding_dim, hidden_dim, n_layers,\n",
        "                        dropout_rate, device)\n",
        "seq2seq_model.to(device)\n",
        "seq2seq_model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU7RkhzVRG5G"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "optimizer = optim.Adam(seq2seq_model.parameters())\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    iterator = tqdm.tqdm(train_data_loader)\n",
        "    seq2seq_model.train()\n",
        "    for batch in iterator:\n",
        "        src = batch[\"de_ids\"].to(device)\n",
        "        trg = batch[\"en_ids\"].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = seq2seq_model(src, trg, 0.5)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        iterator.set_description(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp5acuvvevZ6",
        "outputId": "f98da88f-8613-4f63-e5e8-928a1829aafb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Loss: 2.8463: 100%|██████████| 227/227 [00:29<00:00,  7.73it/s]\n",
            "Epoch 2/10 - Loss: 2.1410: 100%|██████████| 227/227 [00:28<00:00,  8.00it/s]\n",
            "Epoch 3/10 - Loss: 2.1045: 100%|██████████| 227/227 [00:28<00:00,  8.02it/s]\n",
            "Epoch 4/10 - Loss: 2.1536: 100%|██████████| 227/227 [00:28<00:00,  8.04it/s]\n",
            "Epoch 5/10 - Loss: 1.8935: 100%|██████████| 227/227 [00:28<00:00,  7.94it/s]\n",
            "Epoch 6/10 - Loss: 1.8558: 100%|██████████| 227/227 [00:28<00:00,  7.92it/s]\n",
            "Epoch 7/10 - Loss: 1.9211: 100%|██████████| 227/227 [00:28<00:00,  7.99it/s]\n",
            "Epoch 8/10 - Loss: 1.7104: 100%|██████████| 227/227 [00:28<00:00,  8.02it/s]\n",
            "Epoch 9/10 - Loss: 1.9787: 100%|██████████| 227/227 [00:28<00:00,  8.04it/s]\n",
            "Epoch 10/10 - Loss: 1.9717: 100%|██████████| 227/227 [00:28<00:00,  8.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l6modAhRfBG"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fGAAzeXyRix_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae869de1-a18e-4168-9bfb-d8d73b47af08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.1198501139879227\n"
          ]
        }
      ],
      "source": [
        "seq2seq_model.eval()\n",
        "with torch.no_grad():\n",
        "    epoch_loss = 0\n",
        "    for batch in test_data_loader:\n",
        "        src = batch[\"de_ids\"].to(device)\n",
        "        trg = batch[\"en_ids\"].to(device)\n",
        "        output = seq2seq_model(src, trg, 0)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        loss = criterion(output, trg)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "print(f'Test Loss: {epoch_loss / len(test_data_loader)}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d55112d69eb64807a90dc895a509a165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57bc7672f2ed4810aa180a884939b64a",
              "IPY_MODEL_7365d15bfd5f4f74a8f4939894374586",
              "IPY_MODEL_084b183b6eb04407929ef2777ee1a508"
            ],
            "layout": "IPY_MODEL_ecd5f2462cdd4881b78f21d13678c15c"
          }
        },
        "57bc7672f2ed4810aa180a884939b64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b21464b38cd74bb685a482104acbdd5b",
            "placeholder": "​",
            "style": "IPY_MODEL_8996fec23c744b4c817dedfe1a49d865",
            "value": "Map: 100%"
          }
        },
        "7365d15bfd5f4f74a8f4939894374586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0904b220d0e54689b9b773126b0f603c",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c4ed8a230824e7789f88807465916db",
            "value": 1000
          }
        },
        "084b183b6eb04407929ef2777ee1a508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eece2ac489424838b4f11f2c91cd3d00",
            "placeholder": "​",
            "style": "IPY_MODEL_083869e5409d40a48d747bd77d870d44",
            "value": " 1000/1000 [00:00&lt;00:00, 4627.16 examples/s]"
          }
        },
        "ecd5f2462cdd4881b78f21d13678c15c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21464b38cd74bb685a482104acbdd5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8996fec23c744b4c817dedfe1a49d865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0904b220d0e54689b9b773126b0f603c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4ed8a230824e7789f88807465916db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eece2ac489424838b4f11f2c91cd3d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083869e5409d40a48d747bd77d870d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}