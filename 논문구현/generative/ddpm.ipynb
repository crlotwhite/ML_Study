{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:34:18.314653Z",
     "start_time": "2024-08-21T11:34:18.309094Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d45946a7418903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:14:07.154347Z",
     "start_time": "2024-08-21T11:14:07.151518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./configs/ddpm.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./configs/ddpm.yaml\n",
    "\n",
    "batch_size: 32\n",
    "num_epochs: 1\n",
    "total_timesteps: 1000\n",
    "learning_rate: 0.0002\n",
    "\n",
    "img_size: 64\n",
    "img_channels: 3\n",
    "clip_min: -1.0\n",
    "clip_max: 1.0\n",
    "\n",
    "first_conv_channels: 64\n",
    "channel_multiplier:\n",
    "  - 1\n",
    "  - 2\n",
    "  - 4\n",
    "  - 8\n",
    "has_attention:\n",
    "  - false\n",
    "  - false\n",
    "  - true\n",
    "  - true\n",
    "num_res_blocks: 2\n",
    "\n",
    "dataset_name: oxford_flowers102\n",
    "splits:\n",
    "  - train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "262b214e447bd46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:14:07.197371Z",
     "start_time": "2024-08-21T11:14:07.191769Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"./configs/ddpm.yaml\")\n",
    "cfg.widths = [cfg.first_conv_channels * mult for mult in cfg.channel_multiplier]\n",
    "hp = OmegaConf.to_object(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c59bdfe300dce9ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:20:29.927966Z",
     "start_time": "2024-08-21T11:20:29.833714Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 20:42:21.277811: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-08-21 20:42:21.277849: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-08-21 20:42:21.277856: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-08-21 20:42:21.277875: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-21 20:42:21.277896: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "def augment(img):\n",
    "    return tf.image.random_flip_left_right(img)\n",
    "\n",
    "def resize_and_rescale(img, size):\n",
    "    height = tf.shape(img)[0]\n",
    "    width = tf.shape(img)[1]\n",
    "    crop_size = tf.minimum(height, width)\n",
    "    \n",
    "    img = tf.image.crop_to_bounding_box(\n",
    "        img,\n",
    "        (height - crop_size) // 2,\n",
    "        (width - crop_size) // 2,\n",
    "        crop_size,\n",
    "        crop_size\n",
    "    )\n",
    "    \n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    img = tf.image.resize(img, size=size, antialias=True)\n",
    "    \n",
    "    img = img / 127.5 - 1.0\n",
    "    img = tf.clip_by_value(img, hp['clip_min'], hp['clip_max'])\n",
    "    return img\n",
    "\n",
    "def train_preprocessing(x):\n",
    "    img = x['image']\n",
    "    img = resize_and_rescale(img, size=(hp['img_size'], hp['img_size']))\n",
    "    img = augment(img)\n",
    "    return img\n",
    "\n",
    "(ds,) = tfds.load(hp['dataset_name'], split=hp['splits'], with_info=False, shuffle_files=True)\n",
    "train_ds = (ds.map(train_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(hp['batch_size'], drop_remainder=True)\n",
    "            .shuffle(hp['batch_size'] * 2)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5952fbf1fc6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    def __init__(self, beta_start=1e-4, beta_end=0.02, timesteps=1000, clip_min=-1.0, clip_max=1.0):\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.timesteps = timesteps\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max\n",
    "        \n",
    "        self.betas = betas = np.linspace(\n",
    "            beta_start,\n",
    "            beta_end,\n",
    "            timesteps,\n",
    "            dtype=np.float64,\n",
    "        )\n",
    "        \n",
    "        self.num_timesteps = int(timesteps)\n",
    "        \n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
    "        \n",
    "        self.betas = tf.constant(betas, dtype=tf.float32)\n",
    "        self.alphas_cumprod = tf.constant(alphas_cumprod, dtype=tf.float32)\n",
    "        self.alphas_cumprod_prev = tf.constant(alphas_cumprod_prev, dtype=tf.float32)\n",
    "        \n",
    "        self.sqrt_alphas_cumprod = tf.constant(np.sqrt(alphas_cumprod), dtype=tf.float32)\n",
    "        self.sqrt_one_minus_alphas_cumprod = tf.constant(np.sqrt(1.0 - alphas_cumprod), dtype=tf.float32)\n",
    "        self.log_one_minus_alphas_cumprod = tf.constant(np.log(1.0 - alphas_cumprod), dtype=tf.float32)\n",
    "        \n",
    "        self.sqrt_recip_alphas_cumprod = tf.constant(np.sqrt(1.0 / alphas_cumprod), dtype=tf.float32)\n",
    "        self.sqrt_recipm1_alphas_cumprod = tf.constant(np.sqrt(1.0 / alphas_cumprod - 1), dtype=tf.float32)\n",
    "        \n",
    "        posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "        \n",
    "        self.posterior_variance = tf.constant(posterior_variance, dtype=tf.float32)\n",
    "        \n",
    "        self.posterior_log_variance_clipped = tf.constant(np.log(np.maximum(posterior_variance, 1e-20)), dtype=tf.float32)\n",
    "        \n",
    "        self.posterior_mean_coef1 = tf.constant(betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod), dtype=tf.float32)\n",
    "        \n",
    "        self.posterior_mean_coef2 = tf.constant((1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod), dtype=tf.float32)\n",
    "        \n",
    "    def _extract(self, a, t, x_shape):\n",
    "        batch_size = x_shape[0]\n",
    "        out = tf.gather(a, t)\n",
    "        return tf.reshape(out, [batch_size, 1, 1, 1])\n",
    "    \n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        mean = self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start\n",
    "        variance = self._extract(self.log_one_minus_alphas_cumprod, t, x_start_shape)\n",
    "        log_variance = self._extract(self.log_one_minus_alphas_cumprod, t, x_start_shape)\n",
    "        \n",
    "        return mean, variance, log_variance\n",
    "    \n",
    "    def q_sample(self, x_start, t, noise):\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        return self._extract(self.sqrt_alphas_cumprod, t, tf.shape(x_start)) * x_start + self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start_shape) * noise\n",
    "    \n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        return self._extract(self.sqrt_recip_alphas_cumprod, t, x_t_shape) * x_t - self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t_shape) * noise\n",
    "    \n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        posterior_mean = self._extract(self.posterior_mean_coef1, t, x_t_shape) * x_start + self._extract(self.posterior_mean_coef2, t, x_t_shape) * x_t\n",
    "    \n",
    "        posterior_variance = self._extract(self.posterior_variance, t, x_t_shape)\n",
    "        posterior_log_variance_clipped = self._extract(self.posterior_log_variance_clipped, t, x_t_shape)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "    \n",
    "    def p_mean_variance(self, pred_noise, x, t, clip_denoised=True):\n",
    "        x_recon = self.predict_start_from_noise(x, t, pred_noise)\n",
    "        if clip_denoised:\n",
    "            x_recon = tf.clip_by_value(x_recon, self.clip_min, self.clip_max)\n",
    "            \n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "    \n",
    "    def p_sample(self, pred_noise, x, t, clip_denoised=True):\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(pred_noise, x, t, clip_denoised)\n",
    "        noise = tf.random.normal(shape=x.shape, dtype=x.dtype)\n",
    "        nonzero_mask = tf.reshape(1 - tf.cast(tf.equal(t, 0), tf.float32), [tf.shape(x)[0], 1, 1, 1])\n",
    "        \n",
    "        return model_mean + nonzero_mask * tf.exp(0.5 * model_log_variance) * noise\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf0d5ed8267665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_init(scale):\n",
    "    scale = max(scale, 1e-10)\n",
    "    \n",
    "    return keras.initializers.VarianceScaling(scale=scale, mode='fan_avg', distribution='uniform')\n",
    "\n",
    "class AttentionBlock(layers.Layer):\n",
    "    def __init__(self, units, groups=8, **kwargs):\n",
    "        self.units = units\n",
    "        self.groups = groups\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.norm = layers.GroupNormalization(groups=groups)\n",
    "        self.query = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        self.key = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        self.value = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        self.proj = layers.Dense(units, kernel_initializer=kernel_init(0.0))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size, height, width = tf.shape(inputs)[0], tf.shape(inputs)[1], tf.shape(inputs)[2]\n",
    "        scale = tf.cast(self.units, tf.float32) ** (-0.5)\n",
    "\n",
    "        inputs = self.norm(inputs)\n",
    "        q = self.query(inputs)\n",
    "        k = self.key(inputs)\n",
    "        v = self.value(inputs)\n",
    "\n",
    "        attn_score = tf.einsum(\"bhwc, bHWc->bhwHW\", q, k) * scale\n",
    "        attn_score = tf.reshape(attn_score, [batch_size, height, width, height * width])\n",
    "        attn_score = tf.nn.softmax(attn_score, -1)\n",
    "        attn_score = tf.reshape(attn_score, [batch_size, height, width, height, width])\n",
    "\n",
    "        proj = tf.einsum('bhwHW,bHWc->bhwc', attn_score, v)\n",
    "        proj = self.proj(proj)\n",
    "        return inputs + proj\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(layers.Layer):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.half_dim = dim // 2\n",
    "        self.emb = math.log(10000) / (self.half_dim - 1)\n",
    "        self.emb = tf.exp(tf.range(self.half_dim, dtype=tf.float32) * -self.emb)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.cast(inputs, dtype=tf.float32)\n",
    "        emb = inputs[:, None] * self.emb[None, :]\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9cef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(width, groups=8, activation_fn=keras.activations.swish):\n",
    "    def apply(inputs):\n",
    "        x, t = inputs\n",
    "        input_width = x.shape[3]\n",
    "\n",
    "        if input_width == width:\n",
    "            residual = x\n",
    "        else:\n",
    "            residual = layers.Conv2D(width, kernel_size=1, kernel_initializer=kernel_init(1.0))(x)\n",
    "        \n",
    "        temb = activation_fn(t)\n",
    "        temb = layers.Dense(width, kernel_initializer=kernel_init(1.0))(temb)[:, None, None, :]\n",
    "\n",
    "        x = layers.GroupNormalization(groups)(x)\n",
    "        x = activation_fn(x)\n",
    "        x = layers.Conv2d(width, kernel_size=3, padding='same', kernel_initializer=kernel_init(1.0))(x)\n",
    "\n",
    "        x = layers.Add()([x, temb])\n",
    "        x = layers.GroupNormalization(groups)(x)\n",
    "        x = activation_fn(x)\n",
    "        \n",
    "        x = layers.Conv2D(width, kernel_size=3, padding='same', kernel_initializer=kernel_init(0.0))(x)\n",
    "        x = layers.Add()([x, residual])\n",
    "        return x\n",
    "    \n",
    "    return apply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffca6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownSample(width):\n",
    "    def apply(x):\n",
    "        x = layers.Conv2D(width, kernel_size=3, strides=2, padding='same', kernel_initializer=kernel_initializer(1.0))(x)\n",
    "        return x\n",
    "    \n",
    "    return apply\n",
    "\n",
    "def UpSample(width, interpolation='nearest'):\n",
    "    def apply(x):\n",
    "        x = layers.UpSampling2D(size=2, interpolation=interpolation)(x)\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding='same', kernel_initializer=kernel_init(1.0))(x)\n",
    "        return x\n",
    "    \n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeMLP(units, activation_fn=keras.activations.swish):\n",
    "    def apply(inputs):\n",
    "        temb = layers.Dense(units, activation=activation_fn, kernel_initializer=kernel_init(1.0))(inputs)\n",
    "        temb = layers.Dense(units, kernel_initializer=kernel_init(1.0))(temb)\n",
    "        return temb\n",
    "    \n",
    "    return apply\n",
    "\n",
    "def build_model(img_size, img_channels, widths, has_attention, num_res_blocks=2, norm_groups=8, interpolation='nearest', activation_fn=keras.activations.swish):\n",
    "    image_input = layers = layers.Input((img_size, img_size, img_channels), name='image_input')\n",
    "    time_input = keras.Input(shape=(), dtype=tf.int64, name='time_input')\n",
    "\n",
    "    x = layers.Conv2D(hp['first_conv_channels'], kernel_size=(3, 3), padding='same', kernel_initializer=kernel_init(1.0))(image_input)\n",
    "\n",
    "    temb = TimeEmbedding(dim=hp['first_conv_channels'] * 4)(time_input)\n",
    "    temb = TimeMLP(units=hp['first_conv_channels'] * 4, activation_fn=activation_fn)(temb)\n",
    "\n",
    "    skips = [x]\n",
    "\n",
    "    for i in range(len(widths)):\n",
    "        for _ in range(num_res_blocks):\n",
    "            x = ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)(x)([x, temb])\n",
    "            if has_attention[i]:\n",
    "                x = AttentionBlock(widths[i], groups=norm_groups)(x)\n",
    "            \n",
    "            skips.append(x)\n",
    "\n",
    "        if widths[i] != widths[-1]:\n",
    "            x = DownSample(widths[i])(x)\n",
    "            skips.append(x)\n",
    "    \n",
    "    x = ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "    x = AttentionBlock(widths[-1], groups=norm_groups)(x)\n",
    "    x = ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "\n",
    "    for i in reversed(range(len(widths))):\n",
    "        for _ in range(num_res_blocks + 1):\n",
    "            x = layers.Concatenate(axis=-1)([x, skips.pop()])\n",
    "            x = ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "            if has_attention[i]:\n",
    "                x = AttentionBlock(widths[i], groups=norm_groups)(x)\n",
    "        \n",
    "        if i != 0:\n",
    "            x = UpSample(widths[i], interpolation=interpolation)(x)\n",
    "\n",
    "    x = layers.GoupNormalization(groups=norm_groups)(x)\n",
    "    x = layers.Conv2D(3, kernel_size=(3, 3), padding='same', kernel_initializer=kernel_init(0.0))(x)\n",
    "    return keras.Model([image_input, time_input], x, name='unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae534949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
