{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqFbzAw4IJ6M"
      },
      "source": [
        "# 논문 내 설정 요약\n",
        "- **훈련 목적**: 다중 클래스 분류 문제에서 다항 로지스틱 회귀 목표를 최적화\n",
        "- **최적화 방법**: mini-batch gradient descent (mini-batch 크기: 256)과 momentum (momentum 값: 0.9) 사용\n",
        "- **정규화**:\n",
        "  - L2 패널티(가중치 감소) 활용 (L2 패널티 곱셈 인수: \\(5 \\times 10^{-4}\\))\n",
        "  - 첫 두 개의 fully-connected layer에 dropout 정규화 적용 (dropout 비율: 0.5)\n",
        "- **학습률 설정**:\n",
        "  - 초기 학습률: \\(10^{-2}\\)\n",
        "  - 검증 세트 정확도가 개선되지 않을 때마다 학습률을 10배 감소\n",
        "  - 전체 감속 횟수: 3회\n",
        "  - 최종 반복 수: 370K 회 (74 epochs)\n",
        "- **초기화**:\n",
        "  - 초기화의 중요성: 나쁜 초기화는 깊은 신경망에서 gradient 불안정성을 초래하여 학습을 중단시킬 수 있음\n",
        "  - 초기화 방법:\n",
        "    - Configuration A (Table 1)를 무작위 초기화로 훈련\n",
        "    - 더 깊은 아키텍처를 훈련할 때, 첫 4개의 convolutional layer와 마지막 3개의 fully-connected layer를 Configuration A의 레이어로 초기화\n",
        "    - 중간 레이어는 무작위 초깃값으로 초기화\n",
        "  - 가중치 샘플링: 평균 0, 분산 \\(10^{-2}\\)인 정규 분포에서 샘플링\n",
        "  - Bias 초기화: 0으로 초기화\n",
        "  - 참고: Glorot & Bengio(2010) 절차를 통해 사전 학습 없이 초기화 가능\n",
        "- **입력 이미지 전처리**:\n",
        "  - 고정 크기 \\(224 \\times 224\\)의 ConvNet 입력 이미지는 재조정된 훈련 이미지에서 무작위로 자름\n",
        "  - 데이터 증강: 무작위 수평 뒤집기 및 무작위 RGB 색상 변환 적용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4PR0izqGDnV"
      },
      "source": [
        "# Data prepairing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJyYpWiwGAYg",
        "outputId": "07a1bd42-945c-4478-c53f-1f3e49085053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# transforms\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(224),\n",
        "        transforms.RandomCrop((224, 224), padding=4),\n",
        "        transforms.RandomVerticalFlip(0.5),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "valid_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# image size check\n",
        "print(train_set.data.shape)\n",
        "print(valid_set.data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WxVYDmcGG3U"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Vwevlw1PLa0c"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16, self).__init__()\n",
        "\n",
        "        self.convnet = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=512 * 7 * 7, out_features=4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(in_features=4096, out_features=num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convnet(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                init.normal_(m.weight, mean=0, std=0.1)  # 분산이 10^-2인 정규 분포에서 샘플링\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vrj76ZmaGIvI"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "SIhrkeuQPASV",
        "outputId": "53711183-78b6-4206-f3ac-bf5a20cbafec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 - Loss: 2.2737: 100%|██████████| 1563/1563 [09:54<00:00,  2.63it/s]\n",
            "Epoch 2/5 - Loss: 2.4612: 100%|██████████| 1563/1563 [09:53<00:00,  2.63it/s]\n",
            "Epoch 3/5 - Loss: 2.4612: 100%|██████████| 1563/1563 [09:51<00:00,  2.64it/s]\n",
            "Epoch 4/5 - Loss: 2.3987: 100%|██████████| 1563/1563 [09:56<00:00,  2.62it/s]\n",
            "Epoch 5/5 - Loss: 2.3362: 100%|██████████| 1563/1563 [09:49<00:00,  2.65it/s]\n"
          ]
        }
      ],
      "source": [
        "import tqdm, os\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_epochs = 5\n",
        "learning_rate = 0.01\n",
        "batch_size = 32\n",
        "momentum = 0.9\n",
        "weight_decay = 5e-4\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VGG16().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "model_path = \"vgg16_latest.pt\"\n",
        "if os.path.exists(model_path):\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    print(f\"Model loaded from {model_path}\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    iterator = tqdm.tqdm(train_loader)\n",
        "    for data, label in iterator:\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        preds = model(data)\n",
        "        loss = criterion(preds, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iterator.set_description(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # 학습률 감소\n",
        "    if epoch > 0 and epoch % 25 == 0:\n",
        "        learning_rate /= 10\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = learning_rate\n",
        "\n",
        "    torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDVYAhzrUq02"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zU1WgoU5Ukr-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.0992\n"
          ]
        }
      ],
      "source": [
        "num_corr = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, label in valid_loader:\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        preds = model(data).data.max(1)[1]\n",
        "        corr = preds.eq(label.data).sum().item()\n",
        "        num_corr += corr\n",
        "\n",
        "print(f\"Accuracy: {num_corr/len(valid_set)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
