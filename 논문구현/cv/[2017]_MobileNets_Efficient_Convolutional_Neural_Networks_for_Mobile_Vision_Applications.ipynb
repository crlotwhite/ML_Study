{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 구조 설명\n",
        "\n",
        "- **기본 구조**:\n",
        "  - MobileNet은 깊이별 분리 합성곱(depthwise separable convolutions)을 사용하여 구축되며, 첫 번째 층만 전체 합성곱을 사용합니다.\n",
        "  \n",
        "- **모든 층의 특징**:\n",
        "  - 모든 층은 batch normalization(BatchNorm)과 ReLU 비선형성을 가지고 있습니다.\n",
        "  - 최종 완전 연결층(fully connected layer)만 비선형성이 없고 softmax 층으로 분류 작업을 수행합니다.\n",
        "- **층의 대비**:\n",
        "  - 표준 합성곱 층: 3×3 합성곱 + BatchNorm + ReLU.\n",
        "  - 분리 합성곱 층: 깊이별 합성곱(3×3) + BatchNorm + 1×1 합성곱(포인트 와이즈 합성곱) + BatchNorm + ReLU (각 합성곱 층마다).\n",
        "- **다운 샘플링(Down Sampling)**:\n",
        "  - 첫 번째 층과 깊이별 합성곱에서 stride 2를 사용하여 수행됩니다.\n",
        "  - 최종 평균 폴링(Average Pooling)은 공간 해상도를 1로 줄입니다.\n",
        "- **효율적인 연산**:\n",
        "  - MobileNet은 1×1 합성곱(포인트 와이즈 합성곱)에 대부분의 계산을 집중시킵니다.\n",
        "  - 1×1 합성곱은 im2col 재정렬이 필요 없기에 매우 최적화된 GEMM 함수를 통해 직접적으로 구현 가능합니다.\n",
        "- **훈련 방법**:\n",
        "  - TensorFlow를 사용하여 RMSprop 최적화 기법과 비동기식 gradient descent으로 훈련됩니다.\n",
        "  - 과적합을 줄이기 위해 큰 모델 훈련과 달리, 적은 정규화 및 데이터 증강 기법 사용.\n",
        "- **매개변수와 계산시간 분배**:\n",
        "  - MobileNet의 95% 계산 시간은 1×1 합성곱에 사용되며, 이는 전체 매개변수의 75%를 차지합니다(Tables 1, 2 참조)."
      ],
      "metadata": {
        "id": "dhPorP2stkg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prepairing"
      ],
      "metadata": {
        "id": "bAdSmQSerNea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_9YdxG1KrKvM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        # transforms.Resize(224),\n",
        "        # transforms.RandomCrop((224, 224), padding=4),\n",
        "        transforms.RandomCrop((32, 32), padding=4),\n",
        "        transforms.RandomVerticalFlip(0.5),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huktC5kErbPh",
        "outputId": "365365d6-eca5-4d46-ebfc-0530c32b91c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "gD3F3uoJrN8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Depthwise Separable Convolution"
      ],
      "metadata": {
        "id": "P3NlfiTWsa_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DepthwiseSeparableConv, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels,\n",
        "                                   kernel_size=3, padding=1,\n",
        "                                   groups=in_channels, bias=False)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels,\n",
        "                                   kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.depthwise(x)\n",
        "        out = self.pointwise(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "yLn4jE1Wra3d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Alg0eNZvscZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileNet(nn.Module):\n",
        "    class ConvBlock(nn.Module):\n",
        "        def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "            super(MobileNet.ConvBlock, self).__init__()\n",
        "\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels,\n",
        "                                  kernel_size, stride, padding, bias=False)\n",
        "            self.bn = nn.BatchNorm2d(out_channels)\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        def forward(self, x):\n",
        "            out = self.conv(x)\n",
        "            out = self.bn(out)\n",
        "            out = self.relu(out)\n",
        "            return out\n",
        "\n",
        "    class DWConvBlock(nn.Module):\n",
        "        def __init__(self, in_channels, out_channels):\n",
        "            super(MobileNet.DWConvBlock, self).__init__()\n",
        "\n",
        "            self.conv = DepthwiseSeparableConv(in_channels, out_channels)\n",
        "            self.bn = nn.BatchNorm2d(out_channels)\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        def forward(self, x):\n",
        "            out = self.conv(x)\n",
        "            out = self.bn(out)\n",
        "            out = self.relu(out)\n",
        "            return out\n",
        "\n",
        "    class ConvDWConvBlock(nn.Module):\n",
        "        def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0):\n",
        "            super(MobileNet.ConvDWConvBlock, self).__init__()\n",
        "\n",
        "            self.conv_block = MobileNet.ConvBlock(in_channels, out_channels,\n",
        "                                                  kernel_size, stride, padding)\n",
        "            self.dw_conv_block = MobileNet.DWConvBlock(out_channels, out_channels)\n",
        "\n",
        "        def forward(self, x):\n",
        "            out = self.conv_block(x)\n",
        "            out = self.dw_conv_block(out)\n",
        "            return out\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MobileNet, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            self.ConvDWConvBlock(3, 32, stride=2, padding=1),\n",
        "            self.ConvDWConvBlock(32, 64),\n",
        "            self.ConvDWConvBlock(64, 128, kernel_size=1),\n",
        "            self.ConvDWConvBlock(128, 128, kernel_size=1),\n",
        "            self.ConvDWConvBlock(128, 256, kernel_size=1),\n",
        "            self.ConvDWConvBlock(256, 256, kernel_size=1),\n",
        "            self.ConvDWConvBlock(256, 512, kernel_size=1),\n",
        "            self.ConvDWConvBlock(512, 512),\n",
        "            self.DWConvBlock(512, 512),\n",
        "            self.DWConvBlock(512, 512),\n",
        "            self.DWConvBlock(512, 512),\n",
        "            self.DWConvBlock(512, 512),\n",
        "            self.ConvDWConvBlock(512, 512, kernel_size=1),\n",
        "            self.ConvDWConvBlock(512, 1024, kernel_size=1),\n",
        "            self.ConvBlock(1024, 1024, kernel_size=1, stride=1, padding=0),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "jPCZbMfhsco8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "FQTk4S0frOIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MobileNet()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    iterator = tqdm.tqdm(train_loader)\n",
        "    model.train()\n",
        "    for images, labels in iterator:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iterator.set_description(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LKfcZzvrWsf",
        "outputId": "232fcd81-972c-4a66-e14b-4ee0ab4e7045"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/10], Loss: 2.0543: 100%|██████████| 3125/3125 [01:17<00:00, 40.27it/s]\n",
            "Epoch [2/10], Loss: 1.5630: 100%|██████████| 3125/3125 [01:16<00:00, 40.93it/s]\n",
            "Epoch [3/10], Loss: 1.2879: 100%|██████████| 3125/3125 [01:16<00:00, 40.91it/s]\n",
            "Epoch [4/10], Loss: 1.2537: 100%|██████████| 3125/3125 [01:19<00:00, 39.52it/s]\n",
            "Epoch [5/10], Loss: 1.3219: 100%|██████████| 3125/3125 [01:19<00:00, 39.35it/s]\n",
            "Epoch [6/10], Loss: 1.3167: 100%|██████████| 3125/3125 [01:19<00:00, 39.27it/s]\n",
            "Epoch [7/10], Loss: 1.7158: 100%|██████████| 3125/3125 [01:16<00:00, 40.85it/s]\n",
            "Epoch [8/10], Loss: 1.4315: 100%|██████████| 3125/3125 [01:15<00:00, 41.15it/s]\n",
            "Epoch [9/10], Loss: 1.1968: 100%|██████████| 3125/3125 [01:15<00:00, 41.13it/s]\n",
            "Epoch [10/10], Loss: 1.2828: 100%|██████████| 3125/3125 [01:15<00:00, 41.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "BpABWt2DrZR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    iterator = tqdm.tqdm(test_loader)\n",
        "    for images, labels in iterator:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'\\nAccuracy of the model on the test images: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOvrU8XUracI",
        "outputId": "55f8b72a-8abc-43ae-a999-3612c72b264f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:07<00:00, 85.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy of the model on the test images: 55.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}