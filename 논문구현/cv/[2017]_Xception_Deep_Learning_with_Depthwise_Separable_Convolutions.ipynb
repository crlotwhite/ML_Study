{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 개요\n",
        "- **기본 가설**: 깊이 분리 가능한 컨볼루션 레이어를 사용하여 채널 간 상관관계와 공간 상관관계를 완전히 분리할 수 있는지 실험.\n",
        "- **아키텍처 이름**: \"Extreme Inception\"의 줄임말로 Xception이라 명명.\n",
        "  \n",
        "- **구조**\n",
        "  - **36개의 컨볼루션 레이어**: 네트워크의 특징 추출을 담당.\n",
        "  - **로지스틱 회귀 레이어**: 컨볼루션 베이스 후에 사용.\n",
        "  - **선택적 완전 연결 레이어**: 실험적 평가에서 추가 가능.\n",
        "  - **14개의 모듈**: 첫 번째와 마지막 모듈을 제외하고 모두 선형 잔차 연결(Linear Residual Connections)을 가짐.\n",
        "  \n",
        "- **장점**\n",
        "  - **쉽게 정의 및 수정 가능**: Keras 또는 TensorFlow-Slim을 사용하여 30~40 줄의 코드로 아키텍처 정의 가능.\n",
        "  - **복잡도 감소**: VGG-16과 비교하여 정의와 수정이 쉬우며, Inception V2/V3보다 간단.\n",
        "- **오픈 소스 구현**: Keras 및 TensorFlow에서 MIT 라이선스로 제공됨.\n",
        "\n",
        "\n",
        "# Inception V3와의 차이점\n",
        "\n",
        "## 설계 차이점\n",
        "1. **인셉션 모듈 vs. Depthwise Separable Convolutions**\n",
        "   - **Inception V3**:\n",
        "     - 인셉션 모듈을 사용하여 여러 종류의 필터(1x1, 3x3, 5x5)와 풀링 계층을 병렬로 적용합니다.\n",
        "     - 각 모듈은 1x1 합성곱으로 교차-채널 상관관계를 매핑하고, 그 다음 단계에서 공간적 상관관계를 매핑합니다.\n",
        "   - **Xception**:\n",
        "     - Depthwise Separable Convolutions 사용: 한 채널씩 독립적으로 공간적 합성곱을 수행한 후 1x1 합성곱으로 채널을 다시 매핑합니다.\n",
        "     - Xception은 이러한 깊이별 분리 합성곱을 연속적으로 쌓아 올린 구조로 이루어져 있습니다.\n",
        "   \n",
        "2. **연결 방식**\n",
        "   - **Inception V3**: 각 인셉션 모듈을 조합하여 네트워크를 구성합니다.\n",
        "   - **Xception**: 36개의 Depthwise Separable Convolutions 레이어를 선형으로 쌓고, 각 모듈 주변에 선형 잔차 연결(Residual connection)을 사용합니다.\n",
        "   \n",
        "3. **비선형성**\n",
        "   - **Inception V3**: 비선형 활성화 함수(ReLU)를 각 1x1 합성곱과 그 후의 합성곱 후에 추가합니다.\n",
        "   - **Xception**: Depthwise Separable Convolutions에서는 활성화 함수를 사용하지 않는 경우가 많습니다.\n",
        "\n",
        "\n",
        "\n",
        "## 장단점\n",
        "- **Inception V3**\n",
        "  - **장점**:\n",
        "    - 다양한 크기의 필터와 병렬 계층 덕분에 매우 효율적으로 다양한 크기의 특징을 추출할 수 있습니다.\n",
        "  - **단점**:\n",
        "    - 비교적 복잡한 구조로 인해 모델 정의와 수정이 어렵습니다.\n",
        "- **Xception**\n",
        "  - **장점**:\n",
        "    - Depthwise Separable Convolutions로 인해 파라미터 수가 줄어들고 계산 효율성이 높아집니다.\n",
        "    - 선형 구조와 Residual 연결을 사용해 모델 정의와 수정을 쉽게 할 수 있습니다.\n",
        "  - **단점**:\n",
        "    - 강력한 디커플링 가정이 항상 최적의 성능을 보장하지 않을 수 있습니다.\n",
        "\n",
        "## 성능 비교\n",
        "- **파라미터 수**: 두 모델 모두 비슷한 수의 파라미터를 가지고 있습니다.\n",
        "- **ImageNet 데이터셋 성능**:\n",
        "  - Xception은 ImageNet 데이터셋에서 Inception V3와 유사한 성능을 보이거나 약간 더 우수한 성능을 보입니다.\n",
        "- **대규모 이미지 분류 성능 (JFT 데이터셋)**:\n",
        "  - Xception은 Inception V3보다 큰 마진으로 뛰어난 성능을 보입니다. 이는 350만개의 이미지와 17,000개의 클래스로 구성된 대규모 데이터셋에서 확인된 사항입니다.\n",
        "\n",
        "## 결론\n",
        "- **Inception V3**는 다양한 크기의 필터를 병렬로 적용하는 고도의 복잡성을 자랑하며, 충분히 최적화된 모델입니다.\n",
        "- **Xception**은 동일한 파라미터 수로 높은 효율성을 자랑하며, 특히 대규모 데이터셋에서 뛰어난 성능을 보입니다. Depthwise Separable Convolutions을 통해 더 효율적으로 계산할 수 있게 합니다.\n"
      ],
      "metadata": {
        "id": "WskFpFSZSruX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prepairing"
      ],
      "metadata": {
        "id": "A8DLrqi4RvU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "hL5iIqtRR6OB"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        # transforms.Resize(224),\n",
        "        # transforms.RandomCrop((224, 224), padding=4),\n",
        "        transforms.RandomCrop((32, 32), padding=4),\n",
        "        transforms.RandomVerticalFlip(0.5),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "1fpdCSv_SC1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1fe4743-44bc-4315-9cc4-4f422f202376"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "DEZhINsFRx4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Depthwise Separable Convolutions\n",
        "\n",
        "Conv($W$, $y$)$_{(i,j)} = \\sum_{k,l,m}^{K, L, M} W_{(k,l,m)} \\cdot y_{(i+k,j+l,m)}$\n",
        "\n",
        "PointwiseConv($W$, $y$)$_{(i,j)} = \\sum_{m}^{M} W_{m} \\cdot y_{(i,j,m)}$\n",
        "\n",
        "DepthwiseConv($W$, $y$)$_{(i,j)} = \\sum_{k,l}^{K, L} W_{(k,l)} \\odot y_{(i+k,j+l)}$\n",
        "\n",
        "SepConv($W_p$, $W_d$, $y$)$_{(i,j)}$ = $\\text{PointwiseConv}_{(i, j)}(W_{p}, \\text{DepthwiseConv}_{(i, j)}(W_{d}, y))$\n",
        "\n"
      ],
      "metadata": {
        "id": "YIz5iGFdzB1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Depthwise Convolution\n",
        "\n",
        "![](https://raw.githubusercontent.com/seungjunlee96/Depthwise-Separable-Convolution_Pytorch/master/images/depthwise.png)\n",
        "> Depthwise Convolution Diagram  \n",
        "https://github.com/seungjunlee96/Depthwise-Separable-Convolution_Pytorch\n"
      ],
      "metadata": {
        "id": "OGV1akVs1S_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DepthwiseConv(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super(DepthwiseConv, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, in_channels,\n",
        "                          kernel_size=3, padding=1, groups=in_channels,\n",
        "                          bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "PuhaJ--2zBXn"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pointwise Convolution\n",
        "\n",
        "![](https://raw.githubusercontent.com/seungjunlee96/Depthwise-Separable-Convolution_Pytorch/master/images/pointwise.png)\n",
        "\n",
        "> Pointwise Convolution Diagram  \n",
        "https://github.com/seungjunlee96/Depthwise-Separable-Convolution_Pytorch"
      ],
      "metadata": {
        "id": "c1xaAa2C3_wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointwiseConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(PointwiseConv, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "kikCLs2r4Rls"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Depthwise Separable Convolution"
      ],
      "metadata": {
        "id": "ek_Wgl154gsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DepthwiseSeparableConv, self).__init__()\n",
        "        self.depthwise = DepthwiseConv(in_channels)\n",
        "        self.pointwise = PointwiseConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.depthwise(x)\n",
        "        out = self.pointwise(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ys7mrTsj4mXM"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entry Flow"
      ],
      "metadata": {
        "id": "JfvpC9Nz97NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EntryFlow(nn.Module):\n",
        "    class ConvBlock(nn.Module):\n",
        "        def __init__(self, in_channels, out_channels):\n",
        "            super(EntryFlow.ConvBlock, self).__init__()\n",
        "\n",
        "            self.conv_block = nn.Sequential(\n",
        "                DepthwiseSeparableConv(in_channels, out_channels),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(True),\n",
        "                DepthwiseSeparableConv(out_channels, out_channels),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "            )\n",
        "\n",
        "            self.conv_shortcut = nn.Conv2d(in_channels, out_channels,\n",
        "                                           kernel_size=1, stride=2, padding=0)\n",
        "\n",
        "        def forward(self, x):\n",
        "            out = self.conv_block(x)\n",
        "            shortcut = self.conv_shortcut(x)\n",
        "            out = out + shortcut\n",
        "            return out\n",
        "\n",
        "    def __init__(self):\n",
        "        super(EntryFlow, self).__init__()\n",
        "\n",
        "        self.boostrap = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            self.ConvBlock(64, 128),\n",
        "            self.ConvBlock(128, 256),\n",
        "            self.ConvBlock(256, 728)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.boostrap(x)\n",
        "        out = self.conv_blocks(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "E4DtcMp5R6iv"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Middle Flow"
      ],
      "metadata": {
        "id": "mzW-ufev9-CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MiddleFlow(nn.Module):\n",
        "    class ResidualBlock(nn.Module):\n",
        "        def __init__(self, in_channels):\n",
        "            super(MiddleFlow.ResidualBlock, self).__init__()\n",
        "\n",
        "            self.residual_block = nn.Sequential(\n",
        "                nn.ReLU(True),\n",
        "                DepthwiseSeparableConv(in_channels, in_channels),\n",
        "                nn.BatchNorm2d(in_channels),\n",
        "                nn.ReLU(True),\n",
        "                DepthwiseSeparableConv(in_channels, in_channels),\n",
        "                nn.BatchNorm2d(in_channels),\n",
        "                nn.ReLU(True),\n",
        "                DepthwiseSeparableConv(in_channels, in_channels),\n",
        "                nn.BatchNorm2d(in_channels)\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            out = self.residual_block(x)\n",
        "            out = out + x\n",
        "            return out\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MiddleFlow, self).__init__()\n",
        "\n",
        "        self.residual_blocks = nn.Sequential(\n",
        "            *[self.ResidualBlock(728) for _ in range(8)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.residual_blocks(x)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "T61Qwiy5-Byu"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exit Flow"
      ],
      "metadata": {
        "id": "dNe0Zx8g-yqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExitFlow(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExitFlow, self).__init__()\n",
        "\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.ReLU(True),\n",
        "            DepthwiseSeparableConv(728, 728),\n",
        "            nn.BatchNorm2d(728),\n",
        "            nn.ReLU(True),\n",
        "            DepthwiseSeparableConv(728, 1024),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.conv_shortcut = nn.Conv2d(728, 1024,\n",
        "                                       kernel_size=1, stride=2, padding=0)\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            DepthwiseSeparableConv(1024, 1536),\n",
        "            nn.BatchNorm2d(1536),\n",
        "            nn.ReLU(True),\n",
        "            DepthwiseSeparableConv(1536, 2048),\n",
        "            nn.BatchNorm2d(2048),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Linear(2048, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_block1(x)\n",
        "        shortcut = self.conv_shortcut(x)\n",
        "        out = out + shortcut\n",
        "        out = self.conv_block2(out)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "yXNuYGF--03Q"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xception"
      ],
      "metadata": {
        "id": "xpUaPjsyB5XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Xception(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Xception, self).__init__()\n",
        "\n",
        "        self.entry_flow = EntryFlow()\n",
        "        self.middle_flow = MiddleFlow()\n",
        "        self.exit_flow = ExitFlow()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.entry_flow(x)\n",
        "        out = self.middle_flow(out)\n",
        "        out = self.exit_flow(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "W--kB1KBB9Ak"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "HKyCJ4x2R0TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Xception()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    iterator = tqdm.tqdm(train_loader)\n",
        "    model.train()\n",
        "    for images, labels in iterator:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iterator.set_description(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "TwXsYJxVR61-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3b8119-f4af-4f3c-d1b7-cfe38485e1bc"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/10], Loss: 2.0190: 100%|██████████| 3125/3125 [01:51<00:00, 27.99it/s]\n",
            "Epoch [2/10], Loss: 1.6554: 100%|██████████| 3125/3125 [01:49<00:00, 28.57it/s]\n",
            "Epoch [3/10], Loss: 0.9287: 100%|██████████| 3125/3125 [01:49<00:00, 28.54it/s]\n",
            "Epoch [4/10], Loss: 1.7305: 100%|██████████| 3125/3125 [01:51<00:00, 28.09it/s]\n",
            "Epoch [5/10], Loss: 1.1875: 100%|██████████| 3125/3125 [01:51<00:00, 28.03it/s]\n",
            "Epoch [6/10], Loss: 1.0280: 100%|██████████| 3125/3125 [01:51<00:00, 28.13it/s]\n",
            "Epoch [7/10], Loss: 1.1194: 100%|██████████| 3125/3125 [01:51<00:00, 28.13it/s]\n",
            "Epoch [8/10], Loss: 1.5035: 100%|██████████| 3125/3125 [01:50<00:00, 28.36it/s]\n",
            "Epoch [9/10], Loss: 1.5405: 100%|██████████| 3125/3125 [01:48<00:00, 28.68it/s]\n",
            "Epoch [10/10], Loss: 1.0393: 100%|██████████| 3125/3125 [01:49<00:00, 28.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "tBhz_3aIR2oX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "oJzk0pyBRtuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d045df-b08b-4372-f5d7-d0bfcd715d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:08<00:00, 72.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy of the model on the test images: 68.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    iterator = tqdm.tqdm(test_loader)\n",
        "    for images, labels in iterator:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'\\nAccuracy of the model on the test images: {100 * correct / total:.2f}%')\n"
      ]
    }
  ]
}