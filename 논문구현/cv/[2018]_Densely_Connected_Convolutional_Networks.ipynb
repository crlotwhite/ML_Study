{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOfK6EhOOp9L"
      },
      "source": [
        "# 논문 속 데이터 전처리 요약\n",
        "\n",
        "- **CIFAR-10 (C10) 및 CIFAR-100 (C100)**\n",
        "  - *이미지 크기*: 32×32 컬러 자연 이미지\n",
        "  - *클래스 수*: CIFAR-10은 10가지, CIFAR-100은 100가지 클래스\n",
        "  - *데이터셋 크기*:\n",
        "    - CIFAR-10\n",
        "      - 훈련 세트: 50,000 이미지\n",
        "      - 테스트 세트: 10,000 이미지\n",
        "    - CIFAR-100\n",
        "      - 훈련 세트: 50,000 이미지\n",
        "      - 테스트 세트: 10,000 이미지\n",
        "  - *검증 세트*: 훈련 세트에서 5,000 이미지를 홀드 아웃\n",
        "  - *데이터 증강*: 미러링/쉬프팅 (C10+, C100+ 표시에 사용)\n",
        "  - *전처리*: 채널 평균 및 표준 편차로 데이터 정규화\n",
        "  - *최종 런*: 모든 50,000 훈련 이미지를 사용하고 최종 테스트 오류를 보고\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUHOKqLPO_zO"
      },
      "source": [
        "# 논문 속 모델 특징\n",
        "\n",
        "- **전통적인 Convolutional Networks:**\n",
        "  - 레이어 $\\ell$의 $H_{\\ell}(x_{\\ell-1})$ 결과는 다음 $\\ell+1$ 레이어의 입력.\n",
        "  - $ x_{\\ell} = H_{\\ell}(x_{\\ell-1}) $.\n",
        "- **ResNet**:\n",
        "  - 전통적인 네트워크 레이어 연결에 '스킵 연결' 추가.\n",
        "  - 공식: $ x_{\\ell} = H_{\\ell}(x_{\\ell-1}) + x_{\\ell-1} $\n",
        "  - 장점: 그래디언트가 신호를 쉽게 통과하여 역전파 과정에서 정보 손실을 줄임.\n",
        "- **DenseNet**:\n",
        "  - 각 레이어는 모든 이전 레이어의 feature-map을 입력으로 사용.\n",
        "  - 공식: $ x_{\\ell} = H_{\\ell}([x_0, x_1, \\ldots, x_{\\ell-1}]) $\n",
        "  - 이 연결 방식 덕분에 각 레이어는 네트워크의 '집합적 지식'에 접근 가능.\n",
        "  - 장점:\n",
        "    - 그래디언트 소실 문제 해소\n",
        "    - feature 전파 강화\n",
        "    - feature 재사용 권장\n",
        "    - 파라미터 수 감소\n",
        "- **DenseNet의 추가 기능**:\n",
        "  - **Bottleneck Layers**: 1x1 convolution으로 입력 feature-map 수 줄임.\n",
        "  - **Compression**: 네트워크 압축을 통해 모델 효율성 향상.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c89KWTcbPgcm"
      },
      "source": [
        "# Data Preparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8atr2ohtRR3B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeARiZEYPxeJ",
        "outputId": "12ff741d-b04d-4977-b3fe-622c3d8aad4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        # transforms.Resize(224),\n",
        "        # transforms.RandomCrop((224, 224), padding=4),\n",
        "        transforms.RandomCrop((32, 32), padding=4),\n",
        "        transforms.RandomVerticalFlip(0.5),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udj8atQLPgKd"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI6eaGSgTUSr"
      },
      "source": [
        "## DenseLayer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MMxQt-RiTYwQ"
      },
      "outputs": [],
      "source": [
        "import torch.utils.checkpoint as cp\n",
        "\n",
        "\n",
        "class DenseLayer(torch.nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate, bn_size):\n",
        "        super(DenseLayer, self).__init__()\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, bn_size * growth_rate,\n",
        "                      kernel_size=1, stride=1, bias=False),\n",
        "        )\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.BatchNorm2d(bn_size * growth_rate),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                      kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_block1(x)\n",
        "        out = self.conv_block2(out)\n",
        "        return torch.cat((x, out), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1fHm-WWZ-uB"
      },
      "source": [
        "## DenseBlock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8XEbYuZRaARQ"
      },
      "outputs": [],
      "source": [
        "class DenseBlock(torch.nn.Module):\n",
        "    def __init__(self, in_channels, num_layers, growth_rate, bn_size):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            DenseLayer(in_channels + i * growth_rate, growth_rate, bn_size)\n",
        "            for i in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyywRGbmW7W0"
      },
      "source": [
        "## TransitionLayer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1e6RoTbjXAzF"
      },
      "outputs": [],
      "source": [
        "class TransitionLayer(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(TransitionLayer, self).__init__()\n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels // 2,\n",
        "                              kernel_size=1, stride=1, bias=False)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.pool(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3t0KX-oX2Xv"
      },
      "source": [
        "## DenseNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "55vYXj3sX9X1"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, growth_rate, num_layers, num_classes, bn_size):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.bn = nn.BatchNorm2d(3)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv = nn.Conv2d(3, 112,\n",
        "                              kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        dense_blocks = []\n",
        "        features = 112\n",
        "        for num_layer in num_layers:\n",
        "            dense_blocks.append(DenseBlock(features, num_layer, growth_rate, bn_size))\n",
        "            if num_layer != num_layers[-1]:  \n",
        "                dense_blocks.append(TransitionLayer(features + num_layer * growth_rate))\n",
        "                features = (features + num_layer * growth_rate) // 2\n",
        "\n",
        "        self.dense_blocks = nn.Sequential(*dense_blocks)\n",
        "\n",
        "        self.avg_pool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
        "        self.fc = nn.Linear(1030, num_classes)\n",
        "        print(features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.max_pool(x)\n",
        "        x = self.dense_blocks(x)\n",
        "        x = F.relu(x, inplace=True)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        x = torch.softmax(x, dim=1)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZnUBqqEPgCr"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4zneuxFZflNs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 2.1396: 100%|██████████| 782/782 [00:41<00:00, 18.96it/s]\n",
            "Epoch [2/10], Loss: 2.2114: 100%|██████████| 782/782 [00:41<00:00, 18.91it/s]\n",
            "Epoch [3/10], Loss: 2.1727: 100%|██████████| 782/782 [00:40<00:00, 19.10it/s]\n",
            "Epoch [4/10], Loss: 2.0111: 100%|██████████| 782/782 [00:41<00:00, 19.07it/s]\n",
            "Epoch [5/10], Loss: 2.1443: 100%|██████████| 782/782 [00:40<00:00, 19.13it/s]\n",
            "Epoch [6/10], Loss: 2.0263: 100%|██████████| 782/782 [00:40<00:00, 19.15it/s]\n",
            "Epoch [7/10], Loss: 2.3249: 100%|██████████| 782/782 [00:41<00:00, 19.04it/s]\n",
            "Epoch [8/10], Loss: 1.9489: 100%|██████████| 782/782 [00:41<00:00, 18.96it/s]\n",
            "Epoch [9/10], Loss: 1.8978: 100%|██████████| 782/782 [00:41<00:00, 19.03it/s]\n",
            "Epoch [10/10], Loss: 2.0878: 100%|██████████| 782/782 [00:40<00:00, 19.13it/s]\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DenseNet(\n",
        "    growth_rate=32,\n",
        "    num_layers=[6, 12, 24, 16],\n",
        "    num_classes=10,\n",
        "    bn_size=4\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    iterator = tqdm.tqdm(train_loader)\n",
        "    model.train()\n",
        "    for images, labels in iterator:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iterator.set_description(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5yDkl6kPf8c"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3NiQkBQmOoxz",
        "outputId": "54953ac9-93e5-4fd6-f6ab-3c343218a4e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:10<00:00, 14.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy of the model on the test images: 47.29%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    iterator = tqdm.tqdm(test_loader)\n",
        "    for images, labels in iterator:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'\\nAccuracy of the model on the test images: {100 * correct / total:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
