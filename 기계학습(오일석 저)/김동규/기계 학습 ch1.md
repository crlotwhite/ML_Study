# 기계 학습 ch1

## 기계학습이란

기계학습: 컴퓨터가 경험을 통해 학습할 수 있도록 프로그래밍하는 것

주로 예측 (prediction) 문제를 품

예측에는 회귀와 분류가 있음

가로축에 해당하는 패턴을 특징(feature)라고 하며, 벡터의 형테를 가짐

학습(learning) 또는 훈련(training): 서은ㅇ을 개선하면서 최적의 상태에 도달하는 작업

테스트: 훈련집합에 없는 새로운 샘플에 대한 목푯값을 예측하는 과정

일반화 능력: 테스트 집합에 대해 높은 성능을 가진 성질

## 특징 공간에 대한 이해

특징 공간의 차수가 늘어 날수록 매개 변수가 많아져 더 어려운 문제가 된다.

단순 직선 모델로는 서로다른 공간에 속한 항목들을 분류할 수 없음

특징 공간 변환을 통해 좋은 특징 공간을 찾아내는 작업이 필요함

표현 학습: 좋은 특징 공간을 자동으로 찾아냄

신경망 학습 알고리즘이 특징 공간 변환 공식을 자동으로 찾아내 이러한 계층적인 특징 추출 기능 부여함

차원이 증가한다고 수식이나 알고리즘이 바뀔 필요 없음

예) 유클리드 거리 계산 공식
$$
dist(a, b) = \sqrt{\sum_{i=1}^d (a_i-b_i)^2}
$$
차원의 저주: 특징 공간이 거대한데 비해 샘플 수가 적을 경우, 매우 휘소한 분포가 나올 수 밖에 없음

## 데이터에 대한 이해

매니폴드 가정

1. 방대한 공간에서 실제 데이터가 발생하는 곳은 훨씬 작은 부분공간이다.
2. 발생하는 데이터가 심한 변화를 겪지만 일정한 규칙에 따라 메끄럽게 변화한다.

데이터 분포를 잘 표현하는 새로운 특징 공간으로 변환할 수 있다면, 그리 복잡하지 않은 모델로도 높은 성능을 얻을 수 있음

## 간단한 기계 학습의 예

직선 모델을 사용하여 회귀 문제 풀기 (선형 회귀)

추정해야하는 매개변수: w, b
$$
J(\Theta)=\frac{1}{n}\sum_{i=1}^n (f_\Theta(\bold{x_i})-y_i)^2
$$
매개변수 업데이트
$$
\hat{\Theta} = \underset{\Theta}{\mathrm{argmax}}J(\Theta)
$$
목적 함수: 기계학습이 최적의 성능을 찾아가는 데 등대 같은 역할

```

```

$$
입력: 훈련집합 X와 Y \\
출력: 최적의 매개변수 \Theta \\
\\
난수를 생성해 초기 해 \Theta_1을 설정 \\
t=1 \\
while(J(\Theta_t)가 0.0에 충분히 가깝지 않음)\\
J(\Theta_t)가 작아지는 방향 \Delta\Theta_t를 구한다\\
\Theta_{t+1} = \Theta_t + \Delta\Theta_t \\
t = t+1\\
\\
\hat{\Theta} = \Theta_t
$$

수치적 방법: 작은 개선을 반복하여 최적해를 찾아가는 방법

분석적 방법: 훈련 집합의 샘플을 대입하여 한꺼번에 최적해를 구하는 방법

## 모델 선택

과소적합: 모델의 용량이 작아 최적해를 찾아도 큰 오차가 발생하는 경우

과잉적합: 모델의 용량이 지나치게 커서 아주 작은 잡음까지 수용하여 오차자가 큰 경우

기계학습의 목표: 테스트 집합에 대해 높은 성능을 보장하는 프로그램을 만드는 것 (일반화 능력)

데이터 생성 과정과 모델 사이에 큰 차이가 있음 -> 바이어스가 크다

훈련 집합이 바뀌더라도 학습 결과로 얻은 곡선들이 비슷하다 -> 분산이 작다

기계 학습의 목표 -> 낮은 바이어스와 분산을 가진 predictor를 만드는 것

검증집합: 모델을 비교하는데 사용할 별도의 데이터집합

검증 집합을 이요한 모델 선택 과정

1. 긱 모델을 훈련 집합으로 학습
2. 검증 집합으로 학습된 모델 성능 측정
3. 가장 높은 성능을 보인 모델 선택
4. 테스트집합으로 선택된 모델의 성능을 측정

교차검증: 데이터 양이 부족한 상황에서 검증집합을 따로 마련하기 힘든 경우 사용하기 좋은 전략

k개의 그룹을 만들고 하나를 남기고 나머지를 학습에 이용이 과정을 k번 반복하고 이를 평균하여 검증 성능으로 이용

부트스트랩: 알고리즘 난주를 이용하여 검증 집합을 매번 새롭게 구성함

같은 샘플이 여러번 뽑힐 수 있음

## 규제

높은 일반화 능력을 확보하는 기본적인 접근법: 용량이 충분히 큰 모델에 여러가지 규제 기법 적용

- 데이터 증강: 데이터를 더 수집하기 힘든 상황에서 기존 샘플을 변형함으로써 인위적으로 데이터를 확대
- 가중치 감쇠: 극점에서 곡률이 매우 커지는 것을 방지하기 위해 가중치를 작게 유지함

## 기계 학습 유형

지도방식에 따른 구분

- 지도학습: 데이터 입력과 출력이 쌍으로 제공됨 (예: 회귀, 분류)
- 비지도 학습: 입력만 제공 (예: 군집화, 특징 공간 변환)
- 강화 학습: 목표값을 주어 지도 
- 준지도 학습: 소량의 데이터에만 부류 정보를 부여한 후, 부류 정보가 있는 소량의 데이터와 부류 정보가 없는 대량의 데이터를 함께 활용하여 학습

다양한 기준에 따른 구분

- 오프라인 학습과 온라인 학습
  - 오프라인 학습: 데이터베이스 수집, 학습, 예측이라는 순차적인 절차를 충실히 따름
  - 온라인 학습: 지속적으로 발생하는 데이터를 가지고 점진적으로 학습
- 결정론적 학습과 스토캐스틱 학습
  - 결정론적: 같은 입력이 주어지면 항상 같은 결과가 발생
  - 스토캐스틱: 같은 입력이여도 학습할 때마다 새로운 결과 추론
- 분별 모델 학습과 생성 모델 학습
  - 분별 모델: 샘플의 부류를 예측만 함
  - 생성 모델: 확률정보를 통해 기존에 없는 결과를 생성해냄

